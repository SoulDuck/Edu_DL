{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import zip_longest\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference : \n",
    "1. http://louistiao.me/notes/visualizing-and-animating-optimization-algorithms-with-matplotlib/\n",
    "2. http://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 두 변수(X,Y)에 대한 손실함수가 아래와 같은 수식이라고 생각해보자\n",
    "\n",
    "$ Loss(x,y) = (1.5-x+x*y)^2 + (2.25-x+x*y^2)^2+(2.625-x+x*y^3)^2$\n",
    "\n",
    "(사실 이 수식은 Optimization을 평가하는 테스트 Function 중 하나)\n",
    "\n",
    "[Test Functions for Optimization](https://en.wikipedia.org/wiki/Test_functions_for_optimization)\n",
    "\n",
    "다른 수식으로는 \n",
    "* $Loss(x,y) = [1+(x+y+1)^2(19-14x+3x^2-14y+6xy+3y^2)][30+(2x-3y)^2(18-32x+12x^2+48y-36xy+27y^2)]$\n",
    "\n",
    "```python\n",
    "loss = lambda x,y : (\n",
    "    (1+(x+y+1)**2*(19-14*x+3*x**2-14*y+6*x*y+3*y**2)\n",
    "     *(30+(2*x-3*y)**2*(18-32*x+12*x**2+48*y-36*x*y+27*y**2)))\n",
    ")\n",
    "\n",
    "xmin, xmax, xstep = -2.0, 2.0, 0.1\n",
    "ymin, ymax, ystep = -2.0, 2.0, 0.1\n",
    "\n",
    "global_minimum = np.array([[0.0],[-1],[3.0]])\n",
    "init_point = np.array([[-1.5],[1.5],[800000]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lambda x,y : ((1.5-x+x*y)**2\n",
    "                     +(2.25-x+x*y**2)**2\n",
    "                     +(2.625-x+x*y**3)**2)\n",
    "\n",
    "xmin, xmax, xstep = -4.5, 4.5, 0.1\n",
    "ymin, ymax, ystep = -4.5, 4.5, 0.1\n",
    "global_minimum = np.array([[3],[0.5],[0]])\n",
    "init_point = np.array([[3.0],[4.0],[39063]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meshgrid는 벡터 x 및 y에 포함된 좌표를 바탕으로 순서대로, 2차원 좌표를 반환\n",
    "xs, ys = np.meshgrid(np.arange(xmin,xmax+xstep,xstep),\n",
    "         np.arange(ymin,ymax+ystep,ystep))\n",
    "\n",
    "zs = loss(xs,ys) # zs 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손실함수를 3차원 공간에 맵핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = plt.axes(projection='3d', elev=50, azim=-50)\n",
    "\n",
    "ax.plot_surface(xs, ys, zs, norm=LogNorm(), rstride=1, cstride=1, \n",
    "                edgecolor='none', alpha=.8, cmap=plt.cm.jet)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 위와 같은 그래프 아래에서 이 그래프에서의 최솟값은 0이고, \n",
    "\n",
    "최솟값이 되는 곳의 좌표점(x,y)는 바로 (3.0,0.5)이므로 그걸 먼저 위에 찍어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = plt.axes(projection='3d', elev=50, azim=-50)\n",
    "\n",
    "ax.plot_surface(xs, ys, zs, norm=LogNorm(), \n",
    "                rstride=1, cstride=1, \n",
    "                edgecolor='none', alpha=.8, \n",
    "                cmap=plt.cm.jet)\n",
    "\n",
    "ax.plot(*global_minimum, 'r*', markersize=20)\n",
    "\n",
    "ax.plot(*init_point, 'g*', markersize=20)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "ax.set_zlabel('$z$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이걸 윗 방향에서 본다고 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.contour(xs, ys, zs, levels=np.logspace(0, 5, 35), \n",
    "           norm=LogNorm(), cmap=plt.cm.jet)\n",
    "ax.plot(global_minimum[0],global_minimum[1], 'r*', markersize=18)\n",
    "\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "\n",
    "ax.set_xlim((xmin, xmax))\n",
    "ax.set_ylim((ymin, ymax))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마치 등고선 처럼 그림이 그려지게 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_loss_function(xs, ys, zs, path=None):\n",
    "    \"\"\"\n",
    "    3차원 손실 함수를 2차원 등고선 형태로 나타내는 메소드\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.contour(xs, ys, zs, levels=np.logspace(0, 5, 35), \n",
    "               norm=LogNorm(), cmap=plt.cm.jet)\n",
    "\n",
    "    if path is not None:\n",
    "        ax.quiver(path[0,:-1], path[1,:-1], \n",
    "                  path[0,1:]-path[0,:-1], path[1,1:]-path[1,:-1], \n",
    "                  scale_units='xy', angles='xy', scale=1, color='k')\n",
    "        \n",
    "    ax.plot(global_minimum[0],global_minimum[1],\n",
    "            'r*', markersize=18)\n",
    "\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$')\n",
    "\n",
    "    ax.set_xlim((xmin, xmax))\n",
    "    ax.set_ylim((ymin, ymax))\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryAnimation(animation.FuncAnimation):\n",
    "    def __init__(self, paths, labels=[], fig=None, ax=None, frames=None, \n",
    "                 interval=60, repeat_delay=5, blit=True, **kwargs):\n",
    "\n",
    "        if fig is None:\n",
    "            if ax is None:\n",
    "                fig, ax = plt.subplots()\n",
    "            else:\n",
    "                fig = ax.get_figure()\n",
    "        else:\n",
    "            if ax is None:\n",
    "                ax = fig.gca()\n",
    "\n",
    "        self.fig = fig\n",
    "        self.ax = ax\n",
    "        \n",
    "        self.paths = paths\n",
    "\n",
    "        if frames is None:\n",
    "            frames = max(path.shape[1] for path in paths)\n",
    "  \n",
    "        self.lines = [ax.plot([], [], label=label, lw=2)[0] \n",
    "                      for _, label in zip_longest(paths, labels)]\n",
    "        self.points = [ax.plot([], [], 'o', color=line.get_color())[0] \n",
    "                       for line in self.lines]\n",
    "        self.ax.legend(loc='upper left')\n",
    "        super(TrajectoryAnimation, self).__init__(fig, self.animate, init_func=self.init_anim,\n",
    "                                                  frames=frames, interval=interval, blit=blit,\n",
    "                                                  repeat_delay=repeat_delay, **kwargs)\n",
    "\n",
    "    def init_anim(self):\n",
    "        for line, point in zip(self.lines, self.points):\n",
    "            line.set_data([], [])\n",
    "            point.set_data([], [])\n",
    "        return self.lines + self.points\n",
    "\n",
    "    def animate(self, i):\n",
    "        for line, point, path in zip(self.lines, self.points, self.paths):\n",
    "            line.set_data(*path[:2,:i])\n",
    "            point.set_data(*path[:2,i-1:i])\n",
    "        return self.lines + self.points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer 별로 어떤 식으로 움직이는 지 확인해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "n_epoch = 2000\n",
    "frame = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x = tf.Variable(init_point[0,0])\n",
    "    y = tf.Variable(init_point[1,0])\n",
    "\n",
    "    loss = ((1.5-x+x*y)**2\n",
    "             +(2.25-x+x*y**2)**2\n",
    "             +(2.625-x+x*y**3)**2)\n",
    "    \n",
    "    train_op = (tf.train.\n",
    "                GradientDescentOptimizer(learning_rate).\n",
    "                minimize(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    path_ = []\n",
    "    for i in range(n_epoch):\n",
    "        if i % 50 == 0:\n",
    "            p_x = x.eval(sess)\n",
    "            p_y = y.eval(sess)\n",
    "            p_z = sess.run(loss)\n",
    "            point = [p_x, p_y, p_z] # 현재 x,y를 구함\n",
    "            path_.append(point)    \n",
    "            \n",
    "        sess.run(train_op) # 학습\n",
    "        \n",
    "    sgd_path = np.array(path_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_2d_loss_function(xs,ys,zs,sgd_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate에 따라 어떻게 달라지는가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sgd_path(learning_rate):\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        x = tf.Variable(init_point[0,0])\n",
    "        y = tf.Variable(init_point[1,0])\n",
    "\n",
    "        loss = (1.5 - x + x*y)**2+(2.25-x+x*y**2)**2+(2.625-x+x*y**3)*2    \n",
    "\n",
    "        train_op = (tf.train.\n",
    "                    GradientDescentOptimizer(learning_rate).\n",
    "                    minimize(loss))\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        path_ = []\n",
    "        for i in range(n_epoch):\n",
    "            if i % 50 == 0:\n",
    "                p_x = x.eval(sess)\n",
    "                p_y = y.eval(sess)\n",
    "                p_z = sess.run(loss)\n",
    "                point = [p_x, p_y, p_z] # 현재 x,y를 구함\n",
    "                path_.append(point)    \n",
    "\n",
    "            sess.run(train_op) # 학습\n",
    "\n",
    "        sgd_path = np.array(path_).T\n",
    "    return sgd_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_3 = get_sgd_path(1e-3)\n",
    "path_4 = get_sgd_path(1e-4)\n",
    "path_5 = get_sgd_path(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_2d_loss_function(xs,ys,zs)\n",
    "anim = TrajectoryAnimation([path_3,path_4,path_5],\n",
    "                           [\"1e-3\",\"1e-4\",\"1e-5\"], fig=fig,ax=ax)\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "momentum = 0.8\n",
    "n_epoch = 2000\n",
    "frame = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x = tf.Variable(init_point[0,0])\n",
    "    y = tf.Variable(init_point[1,0])\n",
    "\n",
    "    loss = (1.5 - x + x*y)**2+(2.25-x+x*y**2)**2+(2.625-x+x*y**3)*2    \n",
    "    \n",
    "    train_op = (tf.train.MomentumOptimizer(learning_rate, momentum).\n",
    "                minimize(loss))\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    path_ = []\n",
    "    for i in range(n_epoch):\n",
    "        if i % 50 == 0:\n",
    "            p_x = x.eval(sess)\n",
    "            p_y = y.eval(sess)\n",
    "            p_z = sess.run(loss)\n",
    "            point = [p_x, p_y, p_z] # 현재 x,y를 구함\n",
    "            path_.append(point)    \n",
    "            \n",
    "        sess.run(train_op) # 학습\n",
    "        \n",
    "    momentum_path = np.array(path_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_2d_loss_function(xs,ys,zs,momentum_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_momentum_path(learning_rate,momentum):\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        x = tf.Variable(init_point[0,0])\n",
    "        y = tf.Variable(init_point[1,0])\n",
    "\n",
    "        loss = (1.5 - x + x*y)**2+(2.25-x+x*y**2)**2+(2.625-x+x*y**3)*2    \n",
    "\n",
    "        train_op = (tf.train.\n",
    "                    MomentumOptimizer(learning_rate,momentum).\n",
    "                    minimize(loss))\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        path_ = []\n",
    "        for i in range(n_epoch):\n",
    "            if i % 50 == 0:\n",
    "                p_x = x.eval(sess)\n",
    "                p_y = y.eval(sess)\n",
    "                p_z = sess.run(loss)\n",
    "                point = [p_x, p_y, p_z] # 현재 x,y를 구함\n",
    "                path_.append(point)    \n",
    "\n",
    "            sess.run(train_op) # 학습\n",
    "\n",
    "        path = np.array(path_).T\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = get_momentum_path(learning_rate,0.1)\n",
    "path_5 = get_momentum_path(learning_rate,0.5)\n",
    "path_8 = get_momentum_path(learning_rate,0.8)\n",
    "path_9 = get_momentum_path(learning_rate,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_2d_loss_function(xs,ys,zs)\n",
    "anim = TrajectoryAnimation([path_1,path_5,path_8,path_9],\n",
    "                           [\"0.1\",\"0.5\",\"0.8\",\"0.9\"], fig=fig,ax=ax)\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSPropOptimizer 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "decay = 0.9\n",
    "n_epoch = 2000\n",
    "frame = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x = tf.Variable(init_point[0,0])\n",
    "    y = tf.Variable(init_point[1,0])\n",
    "\n",
    "    loss = (1.5 - x + x*y)**2+(2.25-x+x*y**2)**2+(2.625-x+x*y**3)*2    \n",
    "    \n",
    "    train_op = (tf.train.\n",
    "                RMSPropOptimizer(learning_rate,decay=decay).\n",
    "                minimize(loss))\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    path_ = []\n",
    "    for i in range(n_epoch):\n",
    "        if i % 50 == 0:\n",
    "            p_x = x.eval(sess)\n",
    "            p_y = y.eval(sess)\n",
    "            p_z = sess.run(loss)\n",
    "            point = [p_x, p_y, p_z] # 현재 x,y를 구함\n",
    "            path_.append(point)    \n",
    "            \n",
    "        sess.run(train_op) # 학습\n",
    "        \n",
    "    rmsp_path = np.array(path_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_2d_loss_function(xs,ys,zs,rmsp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmsp_path(learning_rate,decay):\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "        x = tf.Variable(init_point[0,0])\n",
    "        y = tf.Variable(init_point[1,0])\n",
    "\n",
    "        loss = (1.5 - x + x*y)**2+(2.25-x+x*y**2)**2+(2.625-x+x*y**3)*2    \n",
    "\n",
    "        train_op = (tf.train.\n",
    "                    RMSPropOptimizer(learning_rate,decay=decay).\n",
    "                    minimize(loss))\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        path_ = []\n",
    "        for i in range(n_epoch):\n",
    "            if i % 50 == 0:\n",
    "                p_x = x.eval(sess)\n",
    "                p_y = y.eval(sess)\n",
    "                p_z = sess.run(loss)\n",
    "                point = [p_x, p_y, p_z] # 현재 x,y를 구함\n",
    "                path_.append(point)    \n",
    "\n",
    "            sess.run(train_op) # 학습\n",
    "\n",
    "        rmsp_path = np.array(path_).T\n",
    "    return rmsp_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_99 = get_rmsp_path(learning_rate,decay=0.99)\n",
    "path_9  = get_rmsp_path(learning_rate,decay=0.9)\n",
    "path_5  = get_rmsp_path(learning_rate,decay=0.5)\n",
    "path_1  = get_rmsp_path(learning_rate,decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_2d_loss_function(xs,ys,zs)\n",
    "anim = TrajectoryAnimation([path_1,path_5,path_9,path_99],\n",
    "                           [\"0.1\",\"0.5\",\"0.9\",\"0.99\"], fig=fig,ax=ax)\n",
    "\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAM Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "n_epoch = 2000\n",
    "frame = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# 첫 위치를 (3.0, 4.0)으로 잡아보자\n",
    "with graph.as_default():\n",
    "    x = tf.Variable(init_point[0,0])\n",
    "    y = tf.Variable(init_point[1,0])\n",
    "\n",
    "    loss = (1.5 - x + x*y)**2+(2.25-x+x*y**2)**2+(2.625-x+x*y**3)*2    \n",
    "    \n",
    "    train_op = (tf.train.AdamOptimizer(learning_rate).\n",
    "                minimize(loss))\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    path_ = []\n",
    "    for i in range(n_epoch):\n",
    "        if i % 50 == 0:\n",
    "            p_x = x.eval(sess)\n",
    "            p_y = y.eval(sess)\n",
    "            p_z = sess.run(loss)\n",
    "            point = [p_x, p_y, p_z] # 현재 x,y를 구함\n",
    "            path_.append(point)    \n",
    "            \n",
    "        sess.run(train_op) # 학습\n",
    "        \n",
    "    adam_path = np.array(path_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_2d_loss_function(xs,ys,zs,adam_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}