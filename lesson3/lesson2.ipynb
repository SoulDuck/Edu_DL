{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 2 1 Single Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0 \t Cost : 1.4311109781265259 \t W : [1.0489569] \t B : [0.02658378] \t\n",
      "Step : 1 \t Cost : 0.017097461968660355 \t W : [0.9926303] \t B : [0.00168428] \t\n",
      "Step : 2 \t Cost : 0.00020664437033701688 \t W : [0.99883497] \t B : [0.00429531] \t\n",
      "Step : 3 \t Cost : 4.767146037920611e-06 \t W : [0.99820423] \t B : [0.00390226] \t\n",
      "Step : 4 \t Cost : 2.2463661935034906e-06 \t W : [0.9983194] \t B : [0.00384012] \t\n",
      "Step : 5 \t Cost : 2.1122252746863523e-06 \t W : [0.9983519] \t B : [0.00374434] \t\n",
      "Step : 6 \t Cost : 2.0115178358537378e-06 \t W : [0.9983924] \t B : [0.00365472] \t\n",
      "Step : 7 \t Cost : 1.9161636828357587e-06 \t W : [0.9984309] \t B : [0.0035668] \t\n",
      "Step : 8 \t Cost : 1.8251872688779258e-06 \t W : [0.9984687] \t B : [0.00348108] \t\n",
      "Step : 9 \t Cost : 1.7382831174472813e-06 \t W : [0.9985055] \t B : [0.00339738] \t\n",
      "Step : 10 \t Cost : 1.6558083189011086e-06 \t W : [0.9985414] \t B : [0.00331572] \t\n",
      "Step : 11 \t Cost : 1.5771929611219093e-06 \t W : [0.99857646] \t B : [0.003236] \t\n",
      "Step : 12 \t Cost : 1.5021345234345063e-06 \t W : [0.9986107] \t B : [0.00315821] \t\n",
      "Step : 13 \t Cost : 1.4309330254036468e-06 \t W : [0.9986441] \t B : [0.00308231] \t\n",
      "Step : 14 \t Cost : 1.362890884593071e-06 \t W : [0.9986767] \t B : [0.00300821] \t\n",
      "Step : 15 \t Cost : 1.2982454791199416e-06 \t W : [0.99870855] \t B : [0.00293589] \t\n",
      "Step : 16 \t Cost : 1.2365520660750917e-06 \t W : [0.99873954] \t B : [0.00286528] \t\n",
      "Step : 17 \t Cost : 1.177652734440926e-06 \t W : [0.9987699] \t B : [0.00279641] \t\n",
      "Step : 18 \t Cost : 1.1217372275496018e-06 \t W : [0.9987994] \t B : [0.00272917] \t\n",
      "Step : 19 \t Cost : 1.0684126436899533e-06 \t W : [0.9988283] \t B : [0.00266359] \t\n",
      "Step : 20 \t Cost : 1.0178598586207954e-06 \t W : [0.9988565] \t B : [0.00259955] \t\n",
      "Step : 21 \t Cost : 9.694903155832435e-07 \t W : [0.99888396] \t B : [0.00253706] \t\n",
      "Step : 22 \t Cost : 9.233463629243488e-07 \t W : [0.9989108] \t B : [0.00247607] \t\n",
      "Step : 23 \t Cost : 8.79633546446712e-07 \t W : [0.998937] \t B : [0.00241656] \t\n",
      "Step : 24 \t Cost : 8.37825893995614e-07 \t W : [0.9989625] \t B : [0.00235844] \t\n",
      "Step : 25 \t Cost : 7.978751455084421e-07 \t W : [0.99898744] \t B : [0.00230174] \t\n",
      "Step : 26 \t Cost : 7.600119715789333e-07 \t W : [0.9990118] \t B : [0.00224642] \t\n",
      "Step : 27 \t Cost : 7.239547699100513e-07 \t W : [0.99903554] \t B : [0.00219241] \t\n",
      "Step : 28 \t Cost : 6.895538149365166e-07 \t W : [0.9990587] \t B : [0.00213971] \t\n",
      "Step : 29 \t Cost : 6.567518653355364e-07 \t W : [0.9990813] \t B : [0.00208827] \t\n",
      "Step : 30 \t Cost : 6.255852440517629e-07 \t W : [0.9991035] \t B : [0.00203809] \t\n",
      "Step : 31 \t Cost : 5.959277586953249e-07 \t W : [0.999125] \t B : [0.00198909] \t\n",
      "Step : 32 \t Cost : 5.675971692653548e-07 \t W : [0.99914604] \t B : [0.00194126] \t\n",
      "Step : 33 \t Cost : 5.406227501225658e-07 \t W : [0.99916655] \t B : [0.00189459] \t\n",
      "Step : 34 \t Cost : 5.149190656084102e-07 \t W : [0.99918664] \t B : [0.00184906] \t\n",
      "Step : 35 \t Cost : 4.903940293843334e-07 \t W : [0.99920607] \t B : [0.00180457] \t\n",
      "Step : 36 \t Cost : 4.671892384067178e-07 \t W : [0.99922526] \t B : [0.00176123] \t\n",
      "Step : 37 \t Cost : 4.44928076603901e-07 \t W : [0.99924386] \t B : [0.00171888] \t\n",
      "Step : 38 \t Cost : 4.2383257436995336e-07 \t W : [0.99926203] \t B : [0.00167757] \t\n",
      "Step : 39 \t Cost : 4.0377199184149504e-07 \t W : [0.9992798] \t B : [0.00163724] \t\n",
      "Step : 40 \t Cost : 3.8456209949799813e-07 \t W : [0.9992971] \t B : [0.00159786] \t\n",
      "Step : 41 \t Cost : 3.662466099285666e-07 \t W : [0.999314] \t B : [0.00155947] \t\n",
      "Step : 42 \t Cost : 3.48853887999212e-07 \t W : [0.9993305] \t B : [0.00152198] \t\n",
      "Step : 43 \t Cost : 3.322616066725459e-07 \t W : [0.99934655] \t B : [0.00148537] \t\n",
      "Step : 44 \t Cost : 3.165359032664128e-07 \t W : [0.9993623] \t B : [0.00144966] \t\n",
      "Step : 45 \t Cost : 3.0147717211548297e-07 \t W : [0.9993776] \t B : [0.00141481] \t\n",
      "Step : 46 \t Cost : 2.871809954285709e-07 \t W : [0.9993926] \t B : [0.00138082] \t\n",
      "Step : 47 \t Cost : 2.7345180342308595e-07 \t W : [0.9994071] \t B : [0.00134759] \t\n",
      "Step : 48 \t Cost : 2.6053791657432157e-07 \t W : [0.9994214] \t B : [0.00131522] \t\n",
      "Step : 49 \t Cost : 2.4814568178044283e-07 \t W : [0.99943537] \t B : [0.00128361] \t\n",
      "Step : 50 \t Cost : 2.3634906654024235e-07 \t W : [0.99944896] \t B : [0.00125275] \t\n",
      "Step : 51 \t Cost : 2.2515816056056792e-07 \t W : [0.9994622] \t B : [0.00122263] \t\n",
      "Step : 52 \t Cost : 2.1445630693506246e-07 \t W : [0.99947506] \t B : [0.00119322] \t\n",
      "Step : 53 \t Cost : 2.0421964563865913e-07 \t W : [0.9994877] \t B : [0.00116454] \t\n",
      "Step : 54 \t Cost : 1.9454419941666856e-07 \t W : [0.99950004] \t B : [0.00113656] \t\n",
      "Step : 55 \t Cost : 1.8530585066400818e-07 \t W : [0.9995121] \t B : [0.00110924] \t\n",
      "Step : 56 \t Cost : 1.7655302997354738e-07 \t W : [0.9995238] \t B : [0.00108258] \t\n",
      "Step : 57 \t Cost : 1.681221561966595e-07 \t W : [0.9995352] \t B : [0.00105654] \t\n",
      "Step : 58 \t Cost : 1.6013240156098618e-07 \t W : [0.9995464] \t B : [0.00103116] \t\n",
      "Step : 59 \t Cost : 1.525600623608625e-07 \t W : [0.9995573] \t B : [0.00100637] \t\n",
      "Step : 60 \t Cost : 1.4530552050473489e-07 \t W : [0.9995679] \t B : [0.00098215] \t\n",
      "Step : 61 \t Cost : 1.384023136097312e-07 \t W : [0.99957836] \t B : [0.00095857] \t\n",
      "Step : 62 \t Cost : 1.3181960412111948e-07 \t W : [0.99958843] \t B : [0.0009355] \t\n",
      "Step : 63 \t Cost : 1.2554573913803324e-07 \t W : [0.9995984] \t B : [0.00091304] \t\n",
      "Step : 64 \t Cost : 1.1959328105604072e-07 \t W : [0.999608] \t B : [0.00089107] \t\n",
      "Step : 65 \t Cost : 1.1392683063604636e-07 \t W : [0.99961746] \t B : [0.00086968] \t\n",
      "Step : 66 \t Cost : 1.0849752385411193e-07 \t W : [0.99962664] \t B : [0.00084876] \t\n",
      "Step : 67 \t Cost : 1.0334633770980872e-07 \t W : [0.9996356] \t B : [0.00082835] \t\n",
      "Step : 68 \t Cost : 9.847835968912477e-08 \t W : [0.9996444] \t B : [0.00080847] \t\n",
      "Step : 69 \t Cost : 9.37433810577204e-08 \t W : [0.99965286] \t B : [0.000789] \t\n",
      "Step : 70 \t Cost : 8.93304203941625e-08 \t W : [0.99966127] \t B : [0.00077007] \t\n",
      "Step : 71 \t Cost : 8.503868542675264e-08 \t W : [0.9996694] \t B : [0.00075155] \t\n",
      "Step : 72 \t Cost : 8.103398840830778e-08 \t W : [0.9996773] \t B : [0.00073348] \t\n",
      "Step : 73 \t Cost : 7.717718375488403e-08 \t W : [0.9996851] \t B : [0.00071587] \t\n",
      "Step : 74 \t Cost : 7.350092801061692e-08 \t W : [0.9996926] \t B : [0.00069864] \t\n",
      "Step : 75 \t Cost : 7.004300783819417e-08 \t W : [0.99970007] \t B : [0.00068187] \t\n",
      "Step : 76 \t Cost : 6.669885266319397e-08 \t W : [0.9997073] \t B : [0.00066547] \t\n",
      "Step : 77 \t Cost : 6.353374004675061e-08 \t W : [0.99971426] \t B : [0.00064946] \t\n",
      "Step : 78 \t Cost : 6.052807322021181e-08 \t W : [0.99972117] \t B : [0.00063387] \t\n",
      "Step : 79 \t Cost : 5.760743349014774e-08 \t W : [0.9997278] \t B : [0.00061861] \t\n",
      "Step : 80 \t Cost : 5.488857368618483e-08 \t W : [0.9997344] \t B : [0.00060377] \t\n",
      "Step : 81 \t Cost : 5.230841892966964e-08 \t W : [0.99974084] \t B : [0.00058926] \t\n",
      "Step : 82 \t Cost : 4.9797964862818844e-08 \t W : [0.999747] \t B : [0.00057506] \t\n",
      "Step : 83 \t Cost : 4.7433090344384254e-08 \t W : [0.9997531] \t B : [0.00056127] \t\n",
      "Step : 84 \t Cost : 4.517223928246494e-08 \t W : [0.999759] \t B : [0.00054777] \t\n",
      "Step : 85 \t Cost : 4.303617018308614e-08 \t W : [0.9997648] \t B : [0.0005346] \t\n",
      "Step : 86 \t Cost : 4.102997763766325e-08 \t W : [0.9997705] \t B : [0.00052177] \t\n",
      "Step : 87 \t Cost : 3.907501877620234e-08 \t W : [0.99977607] \t B : [0.00050923] \t\n",
      "Step : 88 \t Cost : 3.719047469985526e-08 \t W : [0.99978137] \t B : [0.00049696] \t\n",
      "Step : 89 \t Cost : 3.544083426731959e-08 \t W : [0.9997867] \t B : [0.00048504] \t\n",
      "Step : 90 \t Cost : 3.374576351689029e-08 \t W : [0.99979174] \t B : [0.00047336] \t\n",
      "Step : 91 \t Cost : 3.214330490663997e-08 \t W : [0.9997968] \t B : [0.000462] \t\n",
      "Step : 92 \t Cost : 3.061511222313129e-08 \t W : [0.99980164] \t B : [0.00045088] \t\n",
      "Step : 93 \t Cost : 2.9161336456695608e-08 \t W : [0.99980646] \t B : [0.00044005] \t\n",
      "Step : 94 \t Cost : 2.7765375776311885e-08 \t W : [0.99981105] \t B : [0.00042945] \t\n",
      "Step : 95 \t Cost : 2.6482704029717752e-08 \t W : [0.99981564] \t B : [0.00041915] \t\n",
      "Step : 96 \t Cost : 2.5219776489393553e-08 \t W : [0.99982005] \t B : [0.00040906] \t\n",
      "Step : 97 \t Cost : 2.3992868136701873e-08 \t W : [0.99982435] \t B : [0.00039922] \t\n",
      "Step : 98 \t Cost : 2.2862485238306363e-08 \t W : [0.99982864] \t B : [0.00038964] \t\n",
      "Step : 99 \t Cost : 2.1779237968644338e-08 \t W : [0.9998327] \t B : [0.00038026] \t\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test ===\n",
      "X: 5, Y: [4.9995437]\n",
      "X: 2.5, Y: [2.499962]\n"
     ]
    }
   ],
   "source": [
    "# X 와 Y 의 상관관계를 분석하는 기초적인 선형 회귀 모델을 만들고 실행해봅니다.\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "# name: 나중에 텐서보드등으로 값의 변화를 추적하거나 살펴보기 쉽게 하기 위해 이름을 붙여줍니다.\n",
    "X = tf.placeholder(tf.float32, name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "\n",
    "# \n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0), name='w')\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0), name='b')\n",
    "\n",
    "# X 와 Y 의 상관 관계를 분석하기 위한 가설 수식을 작성합니다.\n",
    "# y = W * x + b\n",
    "# W 와 X 가 행렬이 아니므로 tf.matmul 이 아니라 기본 곱셈 기호를 사용했습니다.\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# 손실 함수를 작성합니다.\n",
    "# mean(h - Y)^2 : 예측값과 실제값의 거리를 비용(손실) 함수로 정합니다.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# 텐서플로우에 기본적으로 포함되어 있는 함수를 이용해 경사 하강법 최적화를 수행합니다.\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "# 비용을 최소화 하는 것이 최종 목표\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "# 세션을 생성하고 초기화합니다.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 최적화를 100번 수행합니다.\n",
    "cost_vals=[]\n",
    "for step in range(100):\n",
    "    # sess.run 을 통해 train_op 와 cost 그래프를 계산합니다.\n",
    "    # 이 때, 가설 수식에 넣어야 할 실제값을 feed_dict 을 통해 전달합니다.\n",
    "    _, cost_val = sess.run([train_op, cost], feed_dict={X: x_data, Y: y_data})\n",
    "    cost_vals.append(cost_val)\n",
    "    print('Step : {} \\t Cost : {} \\t W : {} \\t B : {} \\t'.format(step, cost_val, sess.run(W), sess.run(b)))\n",
    "\n",
    "    \n",
    "plt.title('cost')\n",
    "plt.plot(range(100) , cost_vals , c='r')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Test \n",
    "\n",
    "print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
    "print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 Homework 데이터를 \n",
    "학습데이터를 \n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "로 바꾸어 보세요 \n",
    "\n",
    "#2 Homework 데이터를 \n",
    "x_data = [4.0391, 1.3197, 9.5613, 0.5978, 3.5316, 0.1540, 1.6899, 7.3172, 4.5092, 2.9632]\n",
    "y_data = [11.4215, 10.0112, 30.2991, 1.0625, 13.1776, -3.1976, 6.7367, 23.8550, 14.8951, 11.6137]\n",
    "\n",
    "#학습 데이터를 아래와  같이 바꾸어 보세요.\n",
    "import numpy as np\n",
    "num_points = 1000\n",
    "vectors_set = []\n",
    "for i in range(num_points):\n",
    "         x1= np.random.normal(0.0, 0.55)\n",
    "         y1= x1 * 0.1 + 0.3 + np.random.normal(0.0, 0.03)\n",
    "         vectors_set.append([x1, y1])\n",
    "\n",
    "x_data = [v[0] for v in vectors_set]\n",
    "y_data = [v[1] for v in vectors_set]\n",
    "\n",
    "\n",
    "#2 지금 하고 있는 과정은 Regression , Classification 중 무엇일까요? \n",
    "\n",
    "\n",
    "#3 learning rate 을 1 , 0.1 , 0.01 , 0.001 로 바꾸어 보세요 \n",
    "\n",
    "\n",
    "#4 입력값에 100, 1000 ,20000 을 넣어보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 2 Multi Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0\tCost : 0.04338962584733963\tW1 : [0.9298728]\tW2 : [0.85036135]\tB : [0.419412]\t\n",
      "Step : 20\tCost : 0.008890391327440739\tW1 : [0.9412418]\tW2 : [0.9302837]\tB : [0.2235246]\t\n",
      "Step : 40\tCost : 0.0025741304270923138\tW1 : [0.9683827]\tW2 : [0.9624863]\tB : [0.12027644]\t\n",
      "Step : 60\tCost : 0.0007453166181221604\tW1 : [0.9829871]\tW2 : [0.97981423]\tB : [0.06471964]\t\n",
      "Step : 80\tCost : 0.00021580225438810885\tW1 : [0.9908455]\tW2 : [0.98913825]\tB : [0.03482502]\t\n",
      "Step : 100\tCost : 6.248321733437479e-05\tW1 : [0.9950741]\tW2 : [0.99415535]\tB : [0.01873898]\t\n",
      "Step : 120\tCost : 1.8091650417773053e-05\tW1 : [0.9973494]\tW2 : [0.9968551]\tB : [0.01008324]\t\n",
      "Step : 140\tCost : 5.2382456487976015e-06\tW1 : [0.9985737]\tW2 : [0.99830776]\tB : [0.00542566]\t\n",
      "Step : 160\tCost : 1.516641532361973e-06\tW1 : [0.9992326]\tW2 : [0.9990894]\tB : [0.00291949]\t\n",
      "Step : 180\tCost : 4.3907442659474327e-07\tW1 : [0.99958706]\tW2 : [0.99951005]\tB : [0.00157095]\t\n",
      "Step : 200\tCost : 1.2713790908946976e-07\tW1 : [0.99977773]\tW2 : [0.99973637]\tB : [0.0008453]\t\n",
      "Step : 220\tCost : 3.683187799197185e-08\tW1 : [0.99988043]\tW2 : [0.99985814]\tB : [0.00045485]\t\n",
      "Step : 240\tCost : 1.066119903470053e-08\tW1 : [0.9999357]\tW2 : [0.99992365]\tB : [0.00024478]\t\n",
      "Step : 260\tCost : 3.0897950864527957e-09\tW1 : [0.99996537]\tW2 : [0.99995893]\tB : [0.00013173]\t\n",
      "Step : 280\tCost : 8.914639582080497e-10\tW1 : [0.9999814]\tW2 : [0.9999779]\tB : [7.0859685e-05]\t\n",
      "Step : 300\tCost : 2.589786163298413e-10\tW1 : [0.99999]\tW2 : [0.9999881]\tB : [3.810572e-05]\t\n",
      "Step : 320\tCost : 7.460414230830992e-11\tW1 : [0.99999464]\tW2 : [0.9999936]\tB : [2.0515197e-05]\t\n",
      "Step : 340\tCost : 2.1896085639072638e-11\tW1 : [0.9999971]\tW2 : [0.99999654]\tB : [1.0983224e-05]\t\n",
      "Step : 360\tCost : 6.43467484157112e-12\tW1 : [0.9999984]\tW2 : [0.99999815]\tB : [5.904908e-06]\t\n",
      "Step : 380\tCost : 1.7195134205394424e-12\tW1 : [0.9999991]\tW2 : [0.999999]\tB : [3.182168e-06]\t\n",
      "Step : 400\tCost : 6.139089345387483e-13\tW1 : [0.99999946]\tW2 : [0.9999994]\tB : [1.6992046e-06]\t\n",
      "Step : 420\tCost : 1.3926637891948507e-13\tW1 : [0.9999997]\tW2 : [0.9999997]\tB : [9.4580224e-07]\t\n",
      "Step : 440\tCost : 6.821210534347505e-14\tW1 : [0.9999999]\tW2 : [0.9999998]\tB : [6.1201627e-07]\t\n",
      "Step : 460\tCost : 3.4106052671737525e-14\tW1 : [0.9999999]\tW2 : [0.99999994]\tB : [3.1637728e-07]\t\n",
      "Step : 480\tCost : 2.2737367883136385e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [2.3054669e-07]\t\n",
      "Step : 500\tCost : 2.2737367883136385e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.8286302e-07]\t\n",
      "Step : 520\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 540\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 560\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 580\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 600\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 620\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 640\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 660\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 680\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 700\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 720\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 740\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 760\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 780\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 800\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 820\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 840\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 860\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 880\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 900\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 920\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 940\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 960\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 980\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1000\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1020\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1040\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1060\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1080\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1100\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1120\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1140\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1160\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1180\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1200\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1220\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1240\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1260\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1280\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1300\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1320\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1340\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1360\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1380\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1400\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1420\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1440\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1460\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1480\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1500\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1520\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1540\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1560\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1580\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1600\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1620\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1640\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1660\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1680\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1700\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1720\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1740\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1760\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1780\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1800\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1820\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1840\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1860\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1880\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1900\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1920\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1940\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1960\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 1980\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n",
      "Step : 2000\tCost : 1.4210854715202004e-14\tW1 : [1.]\tW2 : [0.99999994]\tB : [1.7809465e-07]\t\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x1_data = [1, 0, 3, 0, 5]\n",
    "x2_data = [0, 2, 0, 4, 0]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "b  = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "# feature 갯수만큼 곱하는 이 부분을 제외하면 one-variable과 다른 곳이 없다\n",
    "hypothesis = W1*x1_data + W2*x2_data + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "rate = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(rate)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(2001):\n",
    "\n",
    "    sess.run(train)\n",
    "\n",
    "    if step%20 == 0:\n",
    "        print('Step : {}\\tCost : {}\\tW1 : {}\\tW2 : {}\\tB : {}\\t'.format(step, sess.run(cost), sess.run(W1), sess.run(W2), sess.run(b)))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}